{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Networks\n",
    "\n",
    "Example: Classifying MNIST Images Using A Siamese Network In PyTorch\n",
    "\n",
    "It's from theb blog of https://becominghuman.ai/siamese-networks-algorithm-applications-and-pytorch-implementation-4ffa3304c18.\n",
    "\n",
    "But there are several typos in the original blog. Have modifies it to run successfully\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import errno\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets.mnist\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "do_learn = True\n",
    "save_frequency = 2\n",
    "batch_size = 16\n",
    "lr = 0.001\n",
    "num_epochs = 10\n",
    "weight_decay = 0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_int(b):\n",
    "    return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "def read_label_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "    assert get_int(data[:4]) == 2049\n",
    "    length = get_int(data[4:8])\n",
    "    parsed = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "    return torch.from_numpy(parsed).view(length).long()\n",
    "\n",
    "def read_image_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "    assert get_int(data[:4]) == 2051\n",
    "    length = get_int(data[4:8])\n",
    "    num_rows = get_int(data[8:12])\n",
    "    num_cols = get_int(data[12:16])\n",
    "    images = []\n",
    "    parsed = np.frombuffer(data, dtype=np.uint8, offset=16)\n",
    "    return torch.from_numpy(parsed).view(length, num_rows, num_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson learned:\n",
    "- Assert. The good coder always add the assert statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important thing is **implementing the siamese network is to build the images pair**.\n",
    "\n",
    "This class use the `torchvision.dataset.mnist.py` as the reference, **the key** is to rewrite the function of getting the image pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_folder = 'processed'\n",
    "# training_file = 'training.pt'\n",
    "# root='.'\n",
    "# data_train_data,data_train_label=torch.load(os.path.join(root,processed_folder,training_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels_class = []\n",
    "# for i in range(10):\n",
    "#     indeces=(data_train_label==i).nonzero().squeeze()\n",
    "#     train_labels_class.append(torch.index_select(data_train_label,0,indeces))\n",
    "# train_labels_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedMNISTPair(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that on each iteration provides two random pairs of\n",
    "    MNIST images. \n",
    "    \n",
    "    One pair is of the same number (positive sample), oneis of \n",
    "    two different numbers (negative sample).\n",
    "    \n",
    "    The code uses the torchvision.dataset as the reference.\n",
    "    \"\"\"\n",
    "    urls = [\n",
    "      'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "      'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "      'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "      'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    raw_folder = 'raw'\n",
    "    processed_folder = 'processed'\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "   \n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' + ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            self.train_data, self.train_labels = torch.load(\n",
    "            os.path.join(self.root, self.processed_folder, self.training_file))\n",
    "\n",
    "            train_labels_class = []\n",
    "            train_data_class = []\n",
    "            for i in range(10):\n",
    "#                 indices = torch.squeeze((self.train_labels == i).nonzero())  # ? maybe it's wrong\n",
    "                indices=(self.train_labels==i).nonzero().squeeze()\n",
    "                train_labels_class.append(torch.index_select(self.train_labels, 0, indices))\n",
    "                train_data_class.append(torch.index_select(self.train_data, 0, indices))\n",
    "\n",
    "            # generate balanced pairs\n",
    "            self.train_data = []\n",
    "            self.train_labels = []\n",
    "            lengths = [x.shape[0] for x in train_labels_class]  # store the amount of each number image\n",
    "            for i in range(10):\n",
    "                for j in range(500): # create 500 pairs\n",
    "                    rnd_cls = random.randint(0,8) # choose random class that is not the same class\n",
    "                    if rnd_cls >= i:\n",
    "                        rnd_cls = rnd_cls + 1\n",
    "                    rnd_dist = random.randint(0, 100)\n",
    "                    # why there are three images in the input? (base image, same class image, non-same class image)?\n",
    "                    self.train_data.append(torch.stack([train_data_class[i][j], train_data_class[i][j+rnd_dist], train_data_class[rnd_cls][j]]))\n",
    "                    self.train_labels.append([1,0])\n",
    "\n",
    "            self.train_data = torch.stack(self.train_data)\n",
    "            self.train_labels = torch.tensor(self.train_labels)\n",
    "\n",
    "        else:\n",
    "            self.test_data, self.test_labels = torch.load(\n",
    "              os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "\n",
    "            test_labels_class = []\n",
    "            test_data_class = []\n",
    "            for i in range(10):\n",
    "                indices = torch.squeeze((self.test_labels == i).nonzero())\n",
    "                test_labels_class.append(torch.index_select(self.test_labels, 0, indices))\n",
    "                test_data_class.append(torch.index_select(self.test_data, 0, indices))\n",
    "\n",
    "            # generate balanced pairs\n",
    "            self.test_data = []\n",
    "            self.test_labels = []\n",
    "            lengths = [x.shape[0] for x in test_labels_class]\n",
    "            for i in range(10):\n",
    "                for j in range(500): # create 500 pairs\n",
    "                    rnd_cls = random.randint(0,8) # choose random class that is not the same class\n",
    "                    if rnd_cls >= i:\n",
    "                        rnd_cls = rnd_cls + 1\n",
    "\n",
    "                rnd_dist = random.randint(0, 100)\n",
    "\n",
    "                self.test_data.append(torch.stack([test_data_class[i][j], test_data_class[i][j+rnd_dist], test_data_class[rnd_cls][j]]))\n",
    "                self.test_labels.append([1,0])\n",
    "\n",
    "            self.test_data = torch.stack(self.test_data)\n",
    "            self.test_labels = torch.tensor(self.test_labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            imgs, target = self.train_data[index], self.train_labels[index]\n",
    "#             print(len(imgs))  # the output is 3\n",
    "        else:\n",
    "            imgs, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        img_ar = []\n",
    "        for i in range(len(imgs)):\n",
    "            img = Image.fromarray(imgs[i].numpy(), mode='L')\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            img_ar.append(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return img_ar, target\n",
    "   \n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "      \n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
    "         os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "   \n",
    "    def download(self):\n",
    "        \"\"\"\n",
    "        Download the MNIST data if it doesn't exist in processed_folder already.\n",
    "        \"\"\"\n",
    "        from six.moves import urllib\n",
    "        import gzip\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        # download files\n",
    "        # In torchvision, this is from util.py\n",
    "        try:\n",
    "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
    "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST:\n",
    "                pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "        for url in self.urls:\n",
    "            print('Downloading ' + url)\n",
    "            data = urllib.request.urlopen(url)\n",
    "            filename = url.rpartition('/')[2]\n",
    "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(data.read())\n",
    "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "                gzip.GzipFile(file_path) as zip_f:\n",
    "                out_f.write(zip_f.read())\n",
    "                os.unlink(file_path)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('Processing...')\n",
    "\n",
    "        training_set = (\n",
    "         read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
    "         read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
    "        )\n",
    "        test_set = (\n",
    "         read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
    "         read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
    "        )\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
    "            torch.save(training_set, f)\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
    "            torch.save(test_set, f)\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = 'train' if self.train is True else 'test'\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    '''\n",
    "    A simple network is built for this task\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 7)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 5)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 5)\n",
    "        self.linear1 = nn.Linear(2304, 512)\n",
    "\n",
    "        self.linear2 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        res = []\n",
    "#         print(len(data))\n",
    "        for i in range(2): # Siamese nets; sharing weights\n",
    "            x = data[i]\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.pool1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv3(x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "            x = x.view(x.shape[0], -1)\n",
    "            x = self.linear1(x)\n",
    "            res.append(F.relu(x))\n",
    "\n",
    "        res = torch.abs(res[1] - res[0])\n",
    "        res = self.linear2(res) # calculate the residual\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (linear1): Linear(in_features=2304, out_features=512, bias=True)\n",
       "  (linear2): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_net=Net()\n",
    "siamese_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the functino of training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, epoch, optimizer):\n",
    "    model.train()\n",
    "   \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        for i in range(len(data)):   # len(data) == 1\n",
    "            data[i] = data[i].to(device)\n",
    "         \n",
    "        optimizer.zero_grad()\n",
    "        output_positive = model(data[:2])  # first two images\n",
    "        output_negative = model(data[0:3:2]) # the first and third image\n",
    "      \n",
    "        target = target.type(torch.LongTensor).to(device)\n",
    "        target_positive = torch.squeeze(target[:,0])\n",
    "        target_negative = torch.squeeze(target[:,1])\n",
    "       \n",
    "        loss_positive = F.cross_entropy(output_positive, target_positive)\n",
    "        loss_negative = F.cross_entropy(output_negative, target_negative)\n",
    "      \n",
    "        loss = loss_positive + loss_negative\n",
    "        loss.backward()\n",
    "      \n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx*batch_size, len(train_loader.dataset), 100. * batch_idx*batch_size / len(train_loader.dataset),\n",
    "            loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "     model.eval()\n",
    "   \n",
    "     with torch.no_grad():\n",
    "        accurate_labels = 0\n",
    "        all_labels = 0\n",
    "        loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            for i in range(len(data)):\n",
    "                data[i] = data[i].to(device)\n",
    "            \n",
    "            output_positive = model(data[:2])\n",
    "            output_negative = model(data[0:3:2])\n",
    "            \n",
    "            target = target.type(torch.LongTensor).to(device)\n",
    "            target_positive = torch.squeeze(target[:,0])\n",
    "            target_negative = torch.squeeze(target[:,1])\n",
    "            \n",
    "            loss_positive = F.cross_entropy(output_positive, target_positive)\n",
    "            loss_negative = F.cross_entropy(output_negative, target_negative)\n",
    "            \n",
    "            loss = loss + loss_positive + loss_negative\n",
    "            \n",
    "            accurate_labels_positive = torch.sum(torch.argmax(output_positive, dim=1) == target_positive).cpu()\n",
    "            accurate_labels_negative = torch.sum(torch.argmax(output_negative, dim=1) == target_negative).cpu()\n",
    "            \n",
    "            accurate_labels = accurate_labels + accurate_labels_positive + accurate_labels_negative\n",
    "            all_labels = all_labels + len(target_positive) + len(target_negative)\n",
    "      \n",
    "        accuracy = 100. * accurate_labels / all_labels\n",
    "        print('Test accuracy: {}/{} ({:.3f}%)\\tLoss: {:.6f}'.format(accurate_labels, all_labels, accuracy, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneshot(model, device, data):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "      \n",
    "        output = model(data)\n",
    "        return torch.squeeze(torch.argmax(output, dim=1)).cpu().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "   \n",
    "    model = Net().to(device)\n",
    "   \n",
    "    if do_learn: # training mode\n",
    "        train_loader = torch.utils.data.DataLoader(BalancedMNISTPair('.', train=True, download=True, transform=trans), batch_size=batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(BalancedMNISTPair('.', train=False, download=True, transform=trans), batch_size=batch_size, shuffle=False)\n",
    "      \n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        for epoch in range(num_epochs):\n",
    "            train(model, device, train_loader, epoch, optimizer)\n",
    "            test(model, device, test_loader)\n",
    "            if epoch & save_frequency == 0:  \n",
    "                # & is a bit-wise operator. 4&2 ==0 since binary for 4 is 100 and binary for 2 is 10\n",
    "                torch.save(model, 'siamese_{:03}.pt'.format(epoch))\n",
    "                \n",
    "    else: # prediction\n",
    "        prediction_loader = torch.utils.data.DataLoader(BalancedMNISTPair('.', train=False, download=True, transform=trans), batch_size=1, shuffle=True)\n",
    "#         model.load_state_dict(torch.load(load_model_path))\n",
    "        model=torch.load(load_model_path)\n",
    "        data = []\n",
    "#         data.extend(next(iter(prediction_loader))[0][:3:2]) # this line tests different number\n",
    "        data.extend(next(iter(prediction_loader))[0][:2]) # this line tests the same number \n",
    "        same = oneshot(model, device, data)\n",
    "        if same > 0:\n",
    "            print('These two images are of the same number')\n",
    "        else:\n",
    "            print('These two images are not of the same number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something wrong with the original code. \n",
    "\n",
    "To save and load model, there are two approaches:\n",
    "- save `model.state_dict` \n",
    "\n",
    "```python\n",
    "# save\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# load\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "\n",
    "```\n",
    "\n",
    "- save entire model\n",
    "\n",
    "```python\n",
    "# save entire model\n",
    "torch.save(model,PATH)\n",
    "\n",
    "# Model class must be defined somewhere\n",
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To debug\n",
    "\n",
    "There is something wrong with the `dataloader`. \n",
    "\n",
    "What's the return of `dataloader`?\n",
    "\n",
    "数据集的构造的时候出了问题。取每个数据的时候似乎没有取到三个图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/5000 (0%)]\tLoss: 1.387695\n",
      "Train Epoch: 0 [160/5000 (3%)]\tLoss: 1.328607\n",
      "Train Epoch: 0 [320/5000 (6%)]\tLoss: 1.337309\n",
      "Train Epoch: 0 [480/5000 (10%)]\tLoss: 1.245728\n",
      "Train Epoch: 0 [640/5000 (13%)]\tLoss: 1.076260\n",
      "Train Epoch: 0 [800/5000 (16%)]\tLoss: 1.331045\n",
      "Train Epoch: 0 [960/5000 (19%)]\tLoss: 1.119653\n",
      "Train Epoch: 0 [1120/5000 (22%)]\tLoss: 1.269907\n",
      "Train Epoch: 0 [1280/5000 (26%)]\tLoss: 0.718807\n",
      "Train Epoch: 0 [1440/5000 (29%)]\tLoss: 1.142576\n",
      "Train Epoch: 0 [1600/5000 (32%)]\tLoss: 1.241787\n",
      "Train Epoch: 0 [1760/5000 (35%)]\tLoss: 1.067343\n",
      "Train Epoch: 0 [1920/5000 (38%)]\tLoss: 0.815318\n",
      "Train Epoch: 0 [2080/5000 (42%)]\tLoss: 0.812550\n",
      "Train Epoch: 0 [2240/5000 (45%)]\tLoss: 1.062404\n",
      "Train Epoch: 0 [2400/5000 (48%)]\tLoss: 0.931154\n",
      "Train Epoch: 0 [2560/5000 (51%)]\tLoss: 0.955884\n",
      "Train Epoch: 0 [2720/5000 (54%)]\tLoss: 0.726036\n",
      "Train Epoch: 0 [2880/5000 (58%)]\tLoss: 1.098595\n",
      "Train Epoch: 0 [3040/5000 (61%)]\tLoss: 0.817837\n",
      "Train Epoch: 0 [3200/5000 (64%)]\tLoss: 0.640061\n",
      "Train Epoch: 0 [3360/5000 (67%)]\tLoss: 0.738132\n",
      "Train Epoch: 0 [3520/5000 (70%)]\tLoss: 0.631178\n",
      "Train Epoch: 0 [3680/5000 (74%)]\tLoss: 0.644467\n",
      "Train Epoch: 0 [3840/5000 (77%)]\tLoss: 1.067377\n",
      "Train Epoch: 0 [4000/5000 (80%)]\tLoss: 0.906405\n",
      "Train Epoch: 0 [4160/5000 (83%)]\tLoss: 0.598501\n",
      "Train Epoch: 0 [4320/5000 (86%)]\tLoss: 0.544782\n",
      "Train Epoch: 0 [4480/5000 (90%)]\tLoss: 0.615603\n",
      "Train Epoch: 0 [4640/5000 (93%)]\tLoss: 0.699746\n",
      "Train Epoch: 0 [4800/5000 (96%)]\tLoss: 0.384716\n",
      "Train Epoch: 0 [4960/5000 (99%)]\tLoss: 0.979280\n",
      "Test accuracy: 19/20 (95.000%)\tLoss: 0.457100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/5000 (0%)]\tLoss: 0.635077\n",
      "Train Epoch: 1 [160/5000 (3%)]\tLoss: 0.331399\n",
      "Train Epoch: 1 [320/5000 (6%)]\tLoss: 0.409805\n",
      "Train Epoch: 1 [480/5000 (10%)]\tLoss: 0.472647\n",
      "Train Epoch: 1 [640/5000 (13%)]\tLoss: 0.553274\n",
      "Train Epoch: 1 [800/5000 (16%)]\tLoss: 0.264550\n",
      "Train Epoch: 1 [960/5000 (19%)]\tLoss: 0.566440\n",
      "Train Epoch: 1 [1120/5000 (22%)]\tLoss: 0.615034\n",
      "Train Epoch: 1 [1280/5000 (26%)]\tLoss: 0.369506\n",
      "Train Epoch: 1 [1440/5000 (29%)]\tLoss: 0.531983\n",
      "Train Epoch: 1 [1600/5000 (32%)]\tLoss: 0.228468\n",
      "Train Epoch: 1 [1760/5000 (35%)]\tLoss: 0.640284\n",
      "Train Epoch: 1 [1920/5000 (38%)]\tLoss: 0.657019\n",
      "Train Epoch: 1 [2080/5000 (42%)]\tLoss: 0.275610\n",
      "Train Epoch: 1 [2240/5000 (45%)]\tLoss: 0.699137\n",
      "Train Epoch: 1 [2400/5000 (48%)]\tLoss: 0.166163\n",
      "Train Epoch: 1 [2560/5000 (51%)]\tLoss: 0.598787\n",
      "Train Epoch: 1 [2720/5000 (54%)]\tLoss: 0.475488\n",
      "Train Epoch: 1 [2880/5000 (58%)]\tLoss: 0.248286\n",
      "Train Epoch: 1 [3040/5000 (61%)]\tLoss: 0.185449\n",
      "Train Epoch: 1 [3200/5000 (64%)]\tLoss: 0.356662\n",
      "Train Epoch: 1 [3360/5000 (67%)]\tLoss: 0.171840\n",
      "Train Epoch: 1 [3520/5000 (70%)]\tLoss: 0.327549\n",
      "Train Epoch: 1 [3680/5000 (74%)]\tLoss: 0.445502\n",
      "Train Epoch: 1 [3840/5000 (77%)]\tLoss: 0.545992\n",
      "Train Epoch: 1 [4000/5000 (80%)]\tLoss: 1.237429\n",
      "Train Epoch: 1 [4160/5000 (83%)]\tLoss: 0.161754\n",
      "Train Epoch: 1 [4320/5000 (86%)]\tLoss: 0.193606\n",
      "Train Epoch: 1 [4480/5000 (90%)]\tLoss: 0.067083\n",
      "Train Epoch: 1 [4640/5000 (93%)]\tLoss: 0.306270\n",
      "Train Epoch: 1 [4800/5000 (96%)]\tLoss: 0.338546\n",
      "Train Epoch: 1 [4960/5000 (99%)]\tLoss: 0.255314\n",
      "Test accuracy: 19/20 (95.000%)\tLoss: 0.204832\n",
      "Train Epoch: 2 [0/5000 (0%)]\tLoss: 0.180894\n",
      "Train Epoch: 2 [160/5000 (3%)]\tLoss: 0.283120\n",
      "Train Epoch: 2 [320/5000 (6%)]\tLoss: 0.561300\n",
      "Train Epoch: 2 [480/5000 (10%)]\tLoss: 0.320248\n",
      "Train Epoch: 2 [640/5000 (13%)]\tLoss: 0.335342\n",
      "Train Epoch: 2 [800/5000 (16%)]\tLoss: 0.062352\n",
      "Train Epoch: 2 [960/5000 (19%)]\tLoss: 0.435113\n",
      "Train Epoch: 2 [1120/5000 (22%)]\tLoss: 0.159184\n",
      "Train Epoch: 2 [1280/5000 (26%)]\tLoss: 0.055231\n",
      "Train Epoch: 2 [1440/5000 (29%)]\tLoss: 0.122361\n",
      "Train Epoch: 2 [1600/5000 (32%)]\tLoss: 0.153208\n",
      "Train Epoch: 2 [1760/5000 (35%)]\tLoss: 0.063645\n",
      "Train Epoch: 2 [1920/5000 (38%)]\tLoss: 0.061981\n",
      "Train Epoch: 2 [2080/5000 (42%)]\tLoss: 0.246655\n",
      "Train Epoch: 2 [2240/5000 (45%)]\tLoss: 0.225794\n",
      "Train Epoch: 2 [2400/5000 (48%)]\tLoss: 0.375475\n",
      "Train Epoch: 2 [2560/5000 (51%)]\tLoss: 0.166421\n",
      "Train Epoch: 2 [2720/5000 (54%)]\tLoss: 0.132035\n",
      "Train Epoch: 2 [2880/5000 (58%)]\tLoss: 0.049095\n",
      "Train Epoch: 2 [3040/5000 (61%)]\tLoss: 0.176867\n",
      "Train Epoch: 2 [3200/5000 (64%)]\tLoss: 0.229748\n",
      "Train Epoch: 2 [3360/5000 (67%)]\tLoss: 0.225071\n",
      "Train Epoch: 2 [3520/5000 (70%)]\tLoss: 0.336437\n",
      "Train Epoch: 2 [3680/5000 (74%)]\tLoss: 0.687877\n",
      "Train Epoch: 2 [3840/5000 (77%)]\tLoss: 0.140921\n",
      "Train Epoch: 2 [4000/5000 (80%)]\tLoss: 0.070106\n",
      "Train Epoch: 2 [4160/5000 (83%)]\tLoss: 0.080695\n",
      "Train Epoch: 2 [4320/5000 (86%)]\tLoss: 0.094519\n",
      "Train Epoch: 2 [4480/5000 (90%)]\tLoss: 0.108449\n",
      "Train Epoch: 2 [4640/5000 (93%)]\tLoss: 0.208450\n",
      "Train Epoch: 2 [4800/5000 (96%)]\tLoss: 0.161434\n",
      "Train Epoch: 2 [4960/5000 (99%)]\tLoss: 0.190556\n",
      "Test accuracy: 19/20 (95.000%)\tLoss: 0.208629\n",
      "Train Epoch: 3 [0/5000 (0%)]\tLoss: 0.146767\n",
      "Train Epoch: 3 [160/5000 (3%)]\tLoss: 0.036134\n",
      "Train Epoch: 3 [320/5000 (6%)]\tLoss: 0.046549\n",
      "Train Epoch: 3 [480/5000 (10%)]\tLoss: 0.332957\n",
      "Train Epoch: 3 [640/5000 (13%)]\tLoss: 0.058703\n",
      "Train Epoch: 3 [800/5000 (16%)]\tLoss: 0.181570\n",
      "Train Epoch: 3 [960/5000 (19%)]\tLoss: 0.197835\n",
      "Train Epoch: 3 [1120/5000 (22%)]\tLoss: 0.168125\n",
      "Train Epoch: 3 [1280/5000 (26%)]\tLoss: 0.098491\n",
      "Train Epoch: 3 [1440/5000 (29%)]\tLoss: 0.046643\n",
      "Train Epoch: 3 [1600/5000 (32%)]\tLoss: 0.087105\n",
      "Train Epoch: 3 [1760/5000 (35%)]\tLoss: 0.132380\n",
      "Train Epoch: 3 [1920/5000 (38%)]\tLoss: 0.032014\n",
      "Train Epoch: 3 [2080/5000 (42%)]\tLoss: 0.083640\n",
      "Train Epoch: 3 [2240/5000 (45%)]\tLoss: 0.093250\n",
      "Train Epoch: 3 [2400/5000 (48%)]\tLoss: 0.043189\n",
      "Train Epoch: 3 [2560/5000 (51%)]\tLoss: 0.056266\n",
      "Train Epoch: 3 [2720/5000 (54%)]\tLoss: 0.259563\n",
      "Train Epoch: 3 [2880/5000 (58%)]\tLoss: 0.178601\n",
      "Train Epoch: 3 [3040/5000 (61%)]\tLoss: 0.035277\n",
      "Train Epoch: 3 [3200/5000 (64%)]\tLoss: 0.012830\n",
      "Train Epoch: 3 [3360/5000 (67%)]\tLoss: 0.281908\n",
      "Train Epoch: 3 [3520/5000 (70%)]\tLoss: 0.042306\n",
      "Train Epoch: 3 [3680/5000 (74%)]\tLoss: 0.083844\n",
      "Train Epoch: 3 [3840/5000 (77%)]\tLoss: 0.041095\n",
      "Train Epoch: 3 [4000/5000 (80%)]\tLoss: 0.115814\n",
      "Train Epoch: 3 [4160/5000 (83%)]\tLoss: 0.263630\n",
      "Train Epoch: 3 [4320/5000 (86%)]\tLoss: 0.344063\n",
      "Train Epoch: 3 [4480/5000 (90%)]\tLoss: 0.037028\n",
      "Train Epoch: 3 [4640/5000 (93%)]\tLoss: 0.037137\n",
      "Train Epoch: 3 [4800/5000 (96%)]\tLoss: 0.104769\n",
      "Train Epoch: 3 [4960/5000 (99%)]\tLoss: 0.022051\n",
      "Test accuracy: 20/20 (100.000%)\tLoss: 0.045101\n",
      "Train Epoch: 4 [0/5000 (0%)]\tLoss: 0.019006\n",
      "Train Epoch: 4 [160/5000 (3%)]\tLoss: 0.155815\n",
      "Train Epoch: 4 [320/5000 (6%)]\tLoss: 0.032785\n",
      "Train Epoch: 4 [480/5000 (10%)]\tLoss: 0.275431\n",
      "Train Epoch: 4 [640/5000 (13%)]\tLoss: 0.024514\n",
      "Train Epoch: 4 [800/5000 (16%)]\tLoss: 0.068330\n",
      "Train Epoch: 4 [960/5000 (19%)]\tLoss: 0.142352\n",
      "Train Epoch: 4 [1120/5000 (22%)]\tLoss: 0.052299\n",
      "Train Epoch: 4 [1280/5000 (26%)]\tLoss: 0.160669\n",
      "Train Epoch: 4 [1440/5000 (29%)]\tLoss: 0.269466\n",
      "Train Epoch: 4 [1600/5000 (32%)]\tLoss: 0.036512\n",
      "Train Epoch: 4 [1760/5000 (35%)]\tLoss: 0.008286\n",
      "Train Epoch: 4 [1920/5000 (38%)]\tLoss: 0.003177\n",
      "Train Epoch: 4 [2080/5000 (42%)]\tLoss: 0.030240\n",
      "Train Epoch: 4 [2240/5000 (45%)]\tLoss: 0.027780\n",
      "Train Epoch: 4 [2400/5000 (48%)]\tLoss: 0.010747\n",
      "Train Epoch: 4 [2560/5000 (51%)]\tLoss: 0.027208\n",
      "Train Epoch: 4 [2720/5000 (54%)]\tLoss: 0.030619\n",
      "Train Epoch: 4 [2880/5000 (58%)]\tLoss: 0.132027\n",
      "Train Epoch: 4 [3040/5000 (61%)]\tLoss: 0.025861\n",
      "Train Epoch: 4 [3200/5000 (64%)]\tLoss: 0.026893\n",
      "Train Epoch: 4 [3360/5000 (67%)]\tLoss: 0.049900\n",
      "Train Epoch: 4 [3520/5000 (70%)]\tLoss: 0.559970\n",
      "Train Epoch: 4 [3680/5000 (74%)]\tLoss: 0.020354\n",
      "Train Epoch: 4 [3840/5000 (77%)]\tLoss: 0.038762\n",
      "Train Epoch: 4 [4000/5000 (80%)]\tLoss: 0.202297\n",
      "Train Epoch: 4 [4160/5000 (83%)]\tLoss: 0.026666\n",
      "Train Epoch: 4 [4320/5000 (86%)]\tLoss: 0.007508\n",
      "Train Epoch: 4 [4480/5000 (90%)]\tLoss: 0.019727\n",
      "Train Epoch: 4 [4640/5000 (93%)]\tLoss: 0.697808\n",
      "Train Epoch: 4 [4800/5000 (96%)]\tLoss: 0.235420\n",
      "Train Epoch: 4 [4960/5000 (99%)]\tLoss: 0.096826\n",
      "Test accuracy: 20/20 (100.000%)\tLoss: 0.059529\n",
      "Train Epoch: 5 [0/5000 (0%)]\tLoss: 0.025228\n",
      "Train Epoch: 5 [160/5000 (3%)]\tLoss: 0.054724\n",
      "Train Epoch: 5 [320/5000 (6%)]\tLoss: 0.083743\n",
      "Train Epoch: 5 [480/5000 (10%)]\tLoss: 0.019576\n",
      "Train Epoch: 5 [640/5000 (13%)]\tLoss: 0.081466\n",
      "Train Epoch: 5 [800/5000 (16%)]\tLoss: 0.039805\n",
      "Train Epoch: 5 [960/5000 (19%)]\tLoss: 0.018564\n",
      "Train Epoch: 5 [1120/5000 (22%)]\tLoss: 0.117891\n",
      "Train Epoch: 5 [1280/5000 (26%)]\tLoss: 0.018633\n",
      "Train Epoch: 5 [1440/5000 (29%)]\tLoss: 0.003698\n",
      "Train Epoch: 5 [1600/5000 (32%)]\tLoss: 0.021471\n",
      "Train Epoch: 5 [1760/5000 (35%)]\tLoss: 0.010167\n",
      "Train Epoch: 5 [1920/5000 (38%)]\tLoss: 0.172491\n",
      "Train Epoch: 5 [2080/5000 (42%)]\tLoss: 0.013740\n",
      "Train Epoch: 5 [2240/5000 (45%)]\tLoss: 0.119715\n",
      "Train Epoch: 5 [2400/5000 (48%)]\tLoss: 0.360133\n",
      "Train Epoch: 5 [2560/5000 (51%)]\tLoss: 0.029164\n",
      "Train Epoch: 5 [2720/5000 (54%)]\tLoss: 0.045892\n",
      "Train Epoch: 5 [2880/5000 (58%)]\tLoss: 0.013565\n",
      "Train Epoch: 5 [3040/5000 (61%)]\tLoss: 0.070235\n",
      "Train Epoch: 5 [3200/5000 (64%)]\tLoss: 0.048013\n",
      "Train Epoch: 5 [3360/5000 (67%)]\tLoss: 0.188366\n",
      "Train Epoch: 5 [3520/5000 (70%)]\tLoss: 0.476809\n",
      "Train Epoch: 5 [3680/5000 (74%)]\tLoss: 0.088341\n",
      "Train Epoch: 5 [3840/5000 (77%)]\tLoss: 0.016737\n",
      "Train Epoch: 5 [4000/5000 (80%)]\tLoss: 0.011016\n",
      "Train Epoch: 5 [4160/5000 (83%)]\tLoss: 0.063862\n",
      "Train Epoch: 5 [4320/5000 (86%)]\tLoss: 0.014331\n",
      "Train Epoch: 5 [4480/5000 (90%)]\tLoss: 0.016676\n",
      "Train Epoch: 5 [4640/5000 (93%)]\tLoss: 0.273692\n",
      "Train Epoch: 5 [4800/5000 (96%)]\tLoss: 0.050545\n",
      "Train Epoch: 5 [4960/5000 (99%)]\tLoss: 0.134093\n",
      "Test accuracy: 20/20 (100.000%)\tLoss: 0.008774\n",
      "Train Epoch: 6 [0/5000 (0%)]\tLoss: 0.006087\n",
      "Train Epoch: 6 [160/5000 (3%)]\tLoss: 0.035371\n",
      "Train Epoch: 6 [320/5000 (6%)]\tLoss: 0.020811\n",
      "Train Epoch: 6 [480/5000 (10%)]\tLoss: 0.202562\n",
      "Train Epoch: 6 [640/5000 (13%)]\tLoss: 0.011096\n",
      "Train Epoch: 6 [800/5000 (16%)]\tLoss: 0.008600\n",
      "Train Epoch: 6 [960/5000 (19%)]\tLoss: 0.011035\n",
      "Train Epoch: 6 [1120/5000 (22%)]\tLoss: 0.001313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [1280/5000 (26%)]\tLoss: 0.017026\n",
      "Train Epoch: 6 [1440/5000 (29%)]\tLoss: 0.028442\n",
      "Train Epoch: 6 [1600/5000 (32%)]\tLoss: 0.048095\n",
      "Train Epoch: 6 [1760/5000 (35%)]\tLoss: 0.050586\n",
      "Train Epoch: 6 [1920/5000 (38%)]\tLoss: 0.015847\n",
      "Train Epoch: 6 [2080/5000 (42%)]\tLoss: 0.081865\n",
      "Train Epoch: 6 [2240/5000 (45%)]\tLoss: 0.018921\n",
      "Train Epoch: 6 [2400/5000 (48%)]\tLoss: 0.006901\n",
      "Train Epoch: 6 [2560/5000 (51%)]\tLoss: 0.046272\n",
      "Train Epoch: 6 [2720/5000 (54%)]\tLoss: 0.378758\n",
      "Train Epoch: 6 [2880/5000 (58%)]\tLoss: 0.027674\n",
      "Train Epoch: 6 [3040/5000 (61%)]\tLoss: 0.244121\n",
      "Train Epoch: 6 [3200/5000 (64%)]\tLoss: 0.279978\n",
      "Train Epoch: 6 [3360/5000 (67%)]\tLoss: 0.027163\n",
      "Train Epoch: 6 [3520/5000 (70%)]\tLoss: 0.071380\n",
      "Train Epoch: 6 [3680/5000 (74%)]\tLoss: 0.030691\n",
      "Train Epoch: 6 [3840/5000 (77%)]\tLoss: 0.054352\n",
      "Train Epoch: 6 [4000/5000 (80%)]\tLoss: 0.255525\n",
      "Train Epoch: 6 [4160/5000 (83%)]\tLoss: 0.045807\n",
      "Train Epoch: 6 [4320/5000 (86%)]\tLoss: 0.264962\n",
      "Train Epoch: 6 [4480/5000 (90%)]\tLoss: 0.011695\n",
      "Train Epoch: 6 [4640/5000 (93%)]\tLoss: 0.005543\n",
      "Train Epoch: 6 [4800/5000 (96%)]\tLoss: 0.401716\n",
      "Train Epoch: 6 [4960/5000 (99%)]\tLoss: 0.007057\n",
      "Test accuracy: 19/20 (95.000%)\tLoss: 0.183692\n",
      "Train Epoch: 7 [0/5000 (0%)]\tLoss: 0.005663\n",
      "Train Epoch: 7 [160/5000 (3%)]\tLoss: 0.004899\n",
      "Train Epoch: 7 [320/5000 (6%)]\tLoss: 0.039335\n",
      "Train Epoch: 7 [480/5000 (10%)]\tLoss: 0.129814\n",
      "Train Epoch: 7 [640/5000 (13%)]\tLoss: 0.005372\n",
      "Train Epoch: 7 [800/5000 (16%)]\tLoss: 0.020900\n",
      "Train Epoch: 7 [960/5000 (19%)]\tLoss: 0.003990\n",
      "Train Epoch: 7 [1120/5000 (22%)]\tLoss: 0.003866\n",
      "Train Epoch: 7 [1280/5000 (26%)]\tLoss: 0.011237\n",
      "Train Epoch: 7 [1440/5000 (29%)]\tLoss: 0.012139\n",
      "Train Epoch: 7 [1600/5000 (32%)]\tLoss: 0.001214\n",
      "Train Epoch: 7 [1760/5000 (35%)]\tLoss: 0.042003\n",
      "Train Epoch: 7 [1920/5000 (38%)]\tLoss: 0.009147\n",
      "Train Epoch: 7 [2080/5000 (42%)]\tLoss: 0.019004\n",
      "Train Epoch: 7 [2240/5000 (45%)]\tLoss: 0.029560\n",
      "Train Epoch: 7 [2400/5000 (48%)]\tLoss: 0.003198\n",
      "Train Epoch: 7 [2560/5000 (51%)]\tLoss: 0.003140\n",
      "Train Epoch: 7 [2720/5000 (54%)]\tLoss: 0.031654\n",
      "Train Epoch: 7 [2880/5000 (58%)]\tLoss: 0.005738\n",
      "Train Epoch: 7 [3040/5000 (61%)]\tLoss: 0.072624\n",
      "Train Epoch: 7 [3200/5000 (64%)]\tLoss: 0.008457\n",
      "Train Epoch: 7 [3360/5000 (67%)]\tLoss: 0.003781\n",
      "Train Epoch: 7 [3520/5000 (70%)]\tLoss: 0.031707\n",
      "Train Epoch: 7 [3680/5000 (74%)]\tLoss: 0.035889\n",
      "Train Epoch: 7 [3840/5000 (77%)]\tLoss: 0.251471\n",
      "Train Epoch: 7 [4000/5000 (80%)]\tLoss: 0.023869\n",
      "Train Epoch: 7 [4160/5000 (83%)]\tLoss: 0.195720\n",
      "Train Epoch: 7 [4320/5000 (86%)]\tLoss: 0.025933\n",
      "Train Epoch: 7 [4480/5000 (90%)]\tLoss: 0.094055\n",
      "Train Epoch: 7 [4640/5000 (93%)]\tLoss: 0.037922\n",
      "Train Epoch: 7 [4800/5000 (96%)]\tLoss: 0.174142\n",
      "Train Epoch: 7 [4960/5000 (99%)]\tLoss: 0.051796\n",
      "Test accuracy: 19/20 (95.000%)\tLoss: 0.172109\n",
      "Train Epoch: 8 [0/5000 (0%)]\tLoss: 0.017147\n",
      "Train Epoch: 8 [160/5000 (3%)]\tLoss: 0.002193\n",
      "Train Epoch: 8 [320/5000 (6%)]\tLoss: 0.000830\n",
      "Train Epoch: 8 [480/5000 (10%)]\tLoss: 0.000693\n",
      "Train Epoch: 8 [640/5000 (13%)]\tLoss: 0.029157\n",
      "Train Epoch: 8 [800/5000 (16%)]\tLoss: 0.003488\n",
      "Train Epoch: 8 [960/5000 (19%)]\tLoss: 0.009432\n",
      "Train Epoch: 8 [1120/5000 (22%)]\tLoss: 0.004388\n",
      "Train Epoch: 8 [1280/5000 (26%)]\tLoss: 0.025582\n",
      "Train Epoch: 8 [1440/5000 (29%)]\tLoss: 0.006675\n",
      "Train Epoch: 8 [1600/5000 (32%)]\tLoss: 0.002995\n",
      "Train Epoch: 8 [1760/5000 (35%)]\tLoss: 0.107974\n",
      "Train Epoch: 8 [1920/5000 (38%)]\tLoss: 0.003105\n",
      "Train Epoch: 8 [2080/5000 (42%)]\tLoss: 0.025434\n",
      "Train Epoch: 8 [2240/5000 (45%)]\tLoss: 0.030909\n",
      "Train Epoch: 8 [2400/5000 (48%)]\tLoss: 0.007776\n",
      "Train Epoch: 8 [2560/5000 (51%)]\tLoss: 0.009797\n",
      "Train Epoch: 8 [2720/5000 (54%)]\tLoss: 0.009067\n",
      "Train Epoch: 8 [2880/5000 (58%)]\tLoss: 0.043085\n",
      "Train Epoch: 8 [3040/5000 (61%)]\tLoss: 0.403526\n",
      "Train Epoch: 8 [3200/5000 (64%)]\tLoss: 0.080376\n",
      "Train Epoch: 8 [3360/5000 (67%)]\tLoss: 0.019183\n",
      "Train Epoch: 8 [3520/5000 (70%)]\tLoss: 0.026420\n",
      "Train Epoch: 8 [3680/5000 (74%)]\tLoss: 0.018679\n",
      "Train Epoch: 8 [3840/5000 (77%)]\tLoss: 0.016985\n",
      "Train Epoch: 8 [4000/5000 (80%)]\tLoss: 0.198073\n",
      "Train Epoch: 8 [4160/5000 (83%)]\tLoss: 0.119651\n",
      "Train Epoch: 8 [4320/5000 (86%)]\tLoss: 0.004304\n",
      "Train Epoch: 8 [4480/5000 (90%)]\tLoss: 0.003405\n",
      "Train Epoch: 8 [4640/5000 (93%)]\tLoss: 0.049781\n",
      "Train Epoch: 8 [4800/5000 (96%)]\tLoss: 0.047304\n",
      "Train Epoch: 8 [4960/5000 (99%)]\tLoss: 0.040559\n",
      "Test accuracy: 20/20 (100.000%)\tLoss: 0.015457\n",
      "Train Epoch: 9 [0/5000 (0%)]\tLoss: 0.141670\n",
      "Train Epoch: 9 [160/5000 (3%)]\tLoss: 0.007610\n",
      "Train Epoch: 9 [320/5000 (6%)]\tLoss: 0.002673\n",
      "Train Epoch: 9 [480/5000 (10%)]\tLoss: 0.021117\n",
      "Train Epoch: 9 [640/5000 (13%)]\tLoss: 0.000575\n",
      "Train Epoch: 9 [800/5000 (16%)]\tLoss: 0.000811\n",
      "Train Epoch: 9 [960/5000 (19%)]\tLoss: 0.011862\n",
      "Train Epoch: 9 [1120/5000 (22%)]\tLoss: 0.011250\n",
      "Train Epoch: 9 [1280/5000 (26%)]\tLoss: 0.001260\n",
      "Train Epoch: 9 [1440/5000 (29%)]\tLoss: 0.020508\n",
      "Train Epoch: 9 [1600/5000 (32%)]\tLoss: 0.002959\n",
      "Train Epoch: 9 [1760/5000 (35%)]\tLoss: 0.004108\n",
      "Train Epoch: 9 [1920/5000 (38%)]\tLoss: 0.015809\n",
      "Train Epoch: 9 [2080/5000 (42%)]\tLoss: 0.412651\n",
      "Train Epoch: 9 [2240/5000 (45%)]\tLoss: 0.001984\n",
      "Train Epoch: 9 [2400/5000 (48%)]\tLoss: 0.020954\n",
      "Train Epoch: 9 [2560/5000 (51%)]\tLoss: 0.100939\n",
      "Train Epoch: 9 [2720/5000 (54%)]\tLoss: 0.000871\n",
      "Train Epoch: 9 [2880/5000 (58%)]\tLoss: 0.051316\n",
      "Train Epoch: 9 [3040/5000 (61%)]\tLoss: 0.018313\n",
      "Train Epoch: 9 [3200/5000 (64%)]\tLoss: 0.000700\n",
      "Train Epoch: 9 [3360/5000 (67%)]\tLoss: 0.020213\n",
      "Train Epoch: 9 [3520/5000 (70%)]\tLoss: 0.041337\n",
      "Train Epoch: 9 [3680/5000 (74%)]\tLoss: 0.000892\n",
      "Train Epoch: 9 [3840/5000 (77%)]\tLoss: 0.080539\n",
      "Train Epoch: 9 [4000/5000 (80%)]\tLoss: 0.000340\n",
      "Train Epoch: 9 [4160/5000 (83%)]\tLoss: 0.295603\n",
      "Train Epoch: 9 [4320/5000 (86%)]\tLoss: 0.020319\n",
      "Train Epoch: 9 [4480/5000 (90%)]\tLoss: 0.015086\n",
      "Train Epoch: 9 [4640/5000 (93%)]\tLoss: 0.064552\n",
      "Train Epoch: 9 [4800/5000 (96%)]\tLoss: 0.002745\n",
      "Train Epoch: 9 [4960/5000 (99%)]\tLoss: 0.015958\n",
      "Test accuracy: 20/20 (100.000%)\tLoss: 0.000724\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These two images are of the same number\n"
     ]
    }
   ],
   "source": [
    "do_learn=False\n",
    "load_model_path='./siamese_009.pt'\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "1. Siamese Networks: Algorithm, Applications And PyTorch Implementation https://becominghuman.ai/siamese-networks-algorithm-applications-and-pytorch-implementation-4ffa3304c18\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
